\section{Sizing}\label{sizing}

A fundamental question is how large the LSST Data Management System must be. To
this end, an analytical model has been developed driven by input from
the requirements specifications. Specifications from the science requirements
and other subsystem designs, and the observing strategy, translate directly
into numbers of detected sources and astronomical objects.
These requirements are found in \cite{LSE-81} with explanatory detail in \cite{LSE-82}.
Key input parameters include camera characteristics, the expected cadence of
observations, the number of observed stars and galaxies expected per band, the
processing operations per data element, the data transfer rates between and
within processing locations, the ingest and query rates of input and output
data, the alert generation rates, and latency and throughput requirements for
all data products.

The model that estimates the compute and storage needed to generate and serve the data products is found in \cite{DMTN-135}.

Communications requirements were developed and modeled for the data transfers
and user query/response load, extrapolated from existing surveys and adjusted
to LSST scale.  These requirements are illustrated in Figure
\ref{fig:near-real-time-flows} for per-visit transfers.  Peak bandwidths assume
a 3~second budget for Summit to Base image transfer and a 5~second budget for
international image transfer.
The peak alert bandwidth assumes 40K~alerts delivered in 15~seconds.

The Summit to Base and Base to NCSA network links have been significantly
over-engineered for four main reasons: first, because the incremental costs of
higher bandwidth once the link has been provisioned at all have been small;
second, to allow key functions, such as interfacing with the Camera Data System
or performing image analysis and measurement to generate alerts, to be
performed in appropriate locations; third, to increase reliability of the
system; and fourth, to simplify certain components such as the Forwarders and
Archivers that interface with or depend on the networks.  A high-speed Base to
NCSA link also enables Data Releases to be transferred south to the Chilean DAC
over the network rather than through physical media, as originally planned,
decoupling science from maintenance and upgrade activities to a greater extent.

The external bandwidth from NCSA to the community alert brokers is baselined at 10~Gbit/sec.
Given an estimate of the peak alert bandwidth of up to 1.8~Gbit/sec \citedsp{LDM-151}, at least 5 community brokers can be supported with this allocation.
Additional external outbound bandwidth is needed for NCSA to deliver results to science users from the US Data Access Center and to deliver bulk downloads to partners; this has been estimated as 52~Gbit/sec in \citeds{LDM-141}.


\begin{figure}
\centering
\includegraphics[width=\textwidth]{images/NearRealTimeDataFlow.pdf}
\caption{Near Real-Time Data Flows}
\label{fig:near-real-time-flows}
\end{figure}

In all of the above, conservative performance improvement factors
were used to extrapolate to the LSST construction and operations phases in
which the technology will be acquired, configured, deployed, operated, and
maintained. A just-in-time acquisition strategy is employed to leverage
favorable cost/performance trends.

The resulting performance and sizing requirements show the DMS to be a
supercomputing-class system with correspondingly large data input/output and
network bandwidth rates.  Despite this size, technology trends show this to be
well within the anticipated performance of commodity-based systems during the
construction and operations time frame.
